"""System monitoring and metrics collection utilities."""
import time
import psutil
import torch
import logging
import smtplib
import os
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import logging
from typing import Dict, Any, Optional, List, Callable
from collections import deque
import threading
from dataclasses import dataclass
from datetime import datetime
import json
from pathlib import Path
import asyncio
from enum import Enum

logger = logging.getLogger(__name__)

class AlertSeverity(Enum):
    """Alert severity levels."""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

class AlertThreshold:
    """Represents a threshold for generating alerts."""
    
    def __init__(self, metric_name: str, threshold: float, severity: AlertSeverity,
                 comparison: str, duration: int = 60, description: str = ""):
        """Initialize alert threshold.
        
        Args:
            metric_name: Name of the metric to monitor.
            threshold: Threshold value.
            severity: Alert severity level.
            comparison: Comparison operator ('>', '<', '>=', '<=', '==').
            duration: Duration in seconds the threshold must be exceeded.
            description: Human-readable description of the threshold.
        """
        self.metric_name = metric_name
        self.threshold = threshold
        self.severity = severity
        self.comparison = comparison
        self.duration = duration
        self.description = description
        self.last_triggered = None
        self.is_triggered = False

    def check(self, value: float, timestamp: float) -> bool:
        """Check if value exceeds threshold.
        
        Args:
            value: Current metric value.
            timestamp: Current timestamp.
            
        Returns:
            bool: True if threshold is exceeded.
        """
        comparisons = {
            '>': lambda x, y: x > y,
            '<': lambda x, y: x < y,
            '>=': lambda x, y: x >= y,
            '<=': lambda x, y: x <= y,
            '==': lambda x, y: x == y
        }
        
        if self.comparison not in comparisons:
            raise ValueError(f"Invalid comparison operator: {self.comparison}")
            
        is_exceeded = comparisons[self.comparison](value, self.threshold)
        
        if is_exceeded and not self.is_triggered:
            if self.last_triggered is None:
                self.last_triggered = timestamp
            elif timestamp - self.last_triggered >= self.duration:
                self.is_triggered = True
                return True
        elif not is_exceeded:
            self.last_triggered = None
            self.is_triggered = False
            
        return False

class Alert:
    """Represents an alert generated by the monitoring system."""
    
    def __init__(self, threshold: AlertThreshold, current_value: float,
                 timestamp: float):
        """Initialize alert.
        
        Args:
            threshold: AlertThreshold that triggered this alert.
            current_value: Current value that triggered the alert.
            timestamp: Timestamp when alert was generated.
        """
        self.threshold = threshold
        self.current_value = current_value
        self.timestamp = timestamp
        self.resolved = False
        self.resolved_at = None

    def resolve(self, timestamp: float):
        """Mark alert as resolved.
        
        Args:
            timestamp: Timestamp when alert was resolved.
        """
        self.resolved = True
        self.resolved_at = timestamp

    def to_dict(self) -> Dict[str, Any]:
        """Convert alert to dictionary.
        
        Returns:
            Dictionary representation of alert.
        """
        return {
            "metric": self.threshold.metric_name,
            "severity": self.threshold.severity.value,
            "threshold": self.threshold.threshold,
            "current_value": self.current_value,
            "description": self.threshold.description,
            "timestamp": self.timestamp,
            "resolved": self.resolved,
            "resolved_at": self.resolved_at
        }

@dataclass
class MetricPoint:
    """Data class for storing metric points."""
    timestamp: float
    value: float
    labels: Dict[str, str] = None
    
    def __post_init__(self):
        if self.labels is None:
            self.labels = {}

class MetricsCollector:
    """Collects and stores system and application metrics. Implements singleton pattern."""
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls, history_size: int = 1000):
        """Create or return the singleton instance."""
        with cls._lock:
            if cls._instance is None:
                instance = super().__new__(cls)
                instance._initialized = False
                instance._history_size = history_size  # Store history size as private attribute
                instance.metrics = {}  # Initialize metrics dict in __new__
                instance._instance_lock = threading.Lock()  # Create instance lock
                cls._instance = instance
            elif history_size != cls._instance._history_size:
                # Update history size if a different one is provided
                with cls._instance._instance_lock:
                    cls._instance._update_history_size(history_size)
            return cls._instance

    def __init__(self, history_size: int = 1000):
        """Initialize metrics collector if not already initialized."""
        if self._initialized:
            return
            
        with self._lock:
            if not self._initialized:
                self.start_time = time.time()
                self._create_standard_metrics()
                self._initialized = True
                
    def _create_standard_metrics(self):
        """Create standard metric queues."""
        self._create_metric_queue('cpu_usage')
        self._create_metric_queue('memory_usage')
        self._create_metric_queue('gpu_memory_usage')
        self._create_metric_queue('model_inference_time')
        self._create_metric_queue('request_latency')
        self._create_metric_queue('requests_per_minute')
        self._create_metric_queue('error_rate')
        
    def _update_history_size(self, new_size: int):
        """Update history size for all metric queues.
        
        Args:
            new_size: New maximum size for metric queues.
        """
        self._history_size = new_size
        for metric_name in self.metrics:
            with self.metrics[metric_name]['lock']:
                # Create new queue with new size and copy over existing items
                old_queue = self.metrics[metric_name]['queue']
                new_queue = deque(old_queue, maxlen=new_size)
                self.metrics[metric_name]['queue'] = new_queue

    def _create_metric_queue(self, name: str) -> None:
        """Create a new metric queue with thread-safe access."""
        self.metrics[name] = {
            'queue': deque(maxlen=self._history_size),
            'lock': threading.Lock()
        }

    def add_metric(self, name: str, value: float, labels: Optional[Dict[str, str]] = None):
        """Add a metric data point."""
        # First check if the metric queue exists
        with self._instance_lock:
            if name not in self.metrics:
                self._create_metric_queue(name)
        
        metric_point = MetricPoint(
            timestamp=time.time(),
            value=value,
            labels=labels or {}
        )
        
        # Use the metric-specific lock for thread safety
        with self.metrics[name]['lock']:
            self.metrics[name]['queue'].append(metric_point)

    def get_metrics(self) -> Dict[str, Any]:
        """Get current metrics summary.
        
        Returns:
            Dictionary containing all metrics.
        """
        with self._instance_lock:
            current_time = time.time()
            uptime = current_time - self.start_time
            
            # Calculate requests per minute
            with self.metrics['request_latency']['lock']:
                recent_request_count = sum(
                    1 for m in self.metrics['request_latency']['queue']
                    if current_time - m.timestamp <= 60
                )
            
            # Calculate error rate
            with self.metrics['error_rate']['lock']:
                recent_errors = sum(
                    1 for m in self.metrics['error_rate']['queue']
                    if current_time - m.timestamp <= 60
                )
            error_rate = (recent_errors / max(recent_request_count, 1)) * 100
            
            return {
                'system': {
                    'uptime': uptime,
                    'cpu_usage': self._get_latest('cpu_usage'),
                    'memory_usage': self._get_latest('memory_usage'),
                    'gpu_memory_usage': self._get_latest('gpu_memory_usage')
                },
                'performance': {
                    'requests_per_minute': recent_request_count,
                    'average_latency': self._get_average('request_latency'),
                    'average_inference_time': self._get_average('model_inference_time'),
                    'error_rate': error_rate
                },
                'historical': {
                    name: self._get_historical(name)
                    for name in self.metrics.keys()
                }
            }

    def _get_latest(self, metric_name: str) -> Optional[float]:
        """Get latest value for a metric."""
        try:
            metric_data = self.metrics[metric_name]
            with metric_data['lock']:
                return metric_data['queue'][-1].value if metric_data['queue'] else None
        except (KeyError, IndexError):
            return None

    def _get_average(self, metric_name: str, window: int = 60) -> Optional[float]:
        """Get average value for a metric over a time window."""
        try:
            metric_data = self.metrics[metric_name]
            current_time = time.time()
            with metric_data['lock']:
                recent_points = [
                    m.value for m in metric_data['queue']
                    if current_time - m.timestamp <= window
                ]
            return sum(recent_points) / len(recent_points) if recent_points else None
        except KeyError:
            return None

    def _get_historical(self, metric_name: str) -> list:
        """Get historical data for a metric."""
        try:
            metric_data = self.metrics[metric_name]
            with metric_data['lock']:
                return [
                    {
                        'timestamp': m.timestamp,
                        'value': m.value,
                        'labels': m.labels
                    }
                    for m in metric_data['queue']
                ]
        except KeyError:
            return []

class SystemMonitor:
    """Monitors system resources and performance."""
    
    def __init__(self, metrics_collector: MetricsCollector):
        """Initialize system monitor.
        
        Args:
            metrics_collector: MetricsCollector instance.
        """
        self.metrics_collector = metrics_collector
        self.monitoring = False
        self.monitor_thread = None

    def start_monitoring(self, interval: float = 1.0):
        """Start system monitoring in background thread.
        
        Args:
            interval: Monitoring interval in seconds.
        """
        if self.monitoring:
            return

        self.monitoring = True
        self.monitor_thread = threading.Thread(
            target=self._monitor_loop,
            args=(interval,),
            daemon=True
        )
        self.monitor_thread.start()
        logger.info("System monitoring started")

    def stop_monitoring(self):
        """Stop system monitoring."""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
            logger.info("System monitoring stopped")

    def _monitor_loop(self, interval: float):
        """Main monitoring loop."""
        while self.monitoring:
            try:
                # CPU usage
                cpu_percent = psutil.cpu_percent(interval=0.1)
                self.metrics_collector.add_metric('cpu_usage', cpu_percent)

                # Memory usage
                memory = psutil.virtual_memory()
                self.metrics_collector.add_metric('memory_usage', memory.percent)

                # GPU memory usage if available
                if torch.cuda.is_available():
                    for i in range(torch.cuda.device_count()):
                        gpu_memory = torch.cuda.memory_allocated(i) / torch.cuda.max_memory_allocated(i)
                        self.metrics_collector.add_metric(
                            'gpu_memory_usage',
                            gpu_memory * 100,
                            {'device': f'cuda:{i}'}
                        )

                time.sleep(interval)
            except Exception as e:
                logger.error(f"Error in monitoring loop: {str(e)}")
                time.sleep(interval)

class PerformanceMonitor:
    """Monitors application performance metrics."""

    def __init__(self, metrics_collector: MetricsCollector):
        """Initialize performance monitor.
        
        Args:
            metrics_collector: MetricsCollector instance.
        """
        self.metrics_collector = metrics_collector
        self._initialize_metrics()
        
    def _initialize_metrics(self):
        """Initialize all performance metric queues."""
        metrics = [
            'request_latency',           # Request processing time
            'model_inference_time',      # Model inference time
            'error_rate',               # Error occurrence rate
            'request_throughput',        # Requests per second
            'request_queue_size',        # Number of requests waiting
            'file_processing_time',      # Time to process uploaded files
            'memory_per_request',        # Memory usage per request
            'cpu_per_request',          # CPU usage per request
            'concurrent_requests',       # Number of concurrent requests
            'request_success_rate'       # Percentage of successful requests
        ]
        
        for metric in metrics:
            if metric not in self.metrics_collector.metrics:
                self.metrics_collector._create_metric_queue(metric)

    def record_request(self, duration: float, endpoint: str, status_code: int = 200,
                      request_size: Optional[int] = None):
        """Record comprehensive request metrics.
        
        Args:
            duration: Request duration in seconds.
            endpoint: API endpoint name.
            status_code: HTTP status code of response.
            request_size: Size of request in bytes.
        """
        timestamp = time.time()
        
        # Record basic request metrics
        self.metrics_collector.add_metric(
            'request_latency',
            duration * 1000,  # Convert to milliseconds
            {
                'endpoint': endpoint,
                'status_code': str(status_code)
            }
        )
        
        # Record success/failure
        is_success = status_code < 400
        self.metrics_collector.add_metric(
            'request_success_rate',
            1.0 if is_success else 0.0,
            {'endpoint': endpoint}
        )
        
        # Record throughput
        self.metrics_collector.add_metric(
            'request_throughput',
            1.0,
            {'endpoint': endpoint}
        )
        
        # Get resource usage for this request
        try:
            process = psutil.Process()
            cpu_percent = process.cpu_percent()
            memory_info = process.memory_info()
            
            self.metrics_collector.add_metric(
                'cpu_per_request',
                cpu_percent,
                {'endpoint': endpoint}
            )
            
            self.metrics_collector.add_metric(
                'memory_per_request',
                memory_info.rss / 1024 / 1024,  # Convert to MB
                {'endpoint': endpoint}
            )
            
        except Exception as e:
            logger.warning(f"Failed to collect resource metrics: {str(e)}")

    def record_inference(self, duration: float, model_name: str, batch_size: int = 1,
                        text_length: Optional[int] = None):
        """Record detailed model inference metrics.
        
        Args:
            duration: Inference duration in seconds.
            model_name: Name of the model used.
            batch_size: Number of items in the batch.
            text_length: Length of processed text.
        """
        metrics = {
            'duration_ms': duration * 1000,
            'batch_size': batch_size
        }
        
        if text_length:
            metrics['text_length'] = text_length
            metrics['tokens_per_second'] = text_length / duration if duration > 0 else 0
            
        self.metrics_collector.add_metric(
            'model_inference_time',
            duration * 1000,  # Convert to milliseconds
            {
                'model': model_name,
                **{f'meta_{k}': str(v) for k, v in metrics.items()}
            }
        )
        
        # Record GPU metrics if available
        if torch.cuda.is_available():
            try:
                gpu_memory = torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated()
                self.metrics_collector.add_metric(
                    'gpu_memory_per_inference',
                    gpu_memory * 100,
                    {'model': model_name}
                )
            except Exception as e:
                logger.warning(f"Failed to collect GPU metrics: {str(e)}")

    def record_error(self, error_type: str, endpoint: str = "", 
                    severity: str = "error", details: Optional[Dict] = None):
        """Record detailed error metrics.
        
        Args:
            error_type: Type of error that occurred.
            endpoint: API endpoint where error occurred.
            severity: Error severity level.
            details: Additional error details.
        """
        self.metrics_collector.add_metric(
            'error_rate',
            1.0,
            {
                'type': error_type,
                'endpoint': endpoint,
                'severity': severity,
                **({f'detail_{k}': str(v) for k, v in details.items()} if details else {})
            }
        )
        
    def record_file_processing(self, duration: float, file_type: str,
                             file_size: int, success: bool = True):
        """Record file processing metrics.
        
        Args:
            duration: Processing duration in seconds.
            file_type: Type of file processed.
            file_size: Size of file in bytes.
            success: Whether processing was successful.
        """
        self.metrics_collector.add_metric(
            'file_processing_time',
            duration * 1000,  # Convert to milliseconds
            {
                'file_type': file_type,
                'size_mb': str(file_size / 1024 / 1024),
                'success': str(success)
            }
        )

class AlertManager:
    """Manages system alerts and notifications."""
    
    def __init__(self, metrics_collector: 'MetricsCollector'):
        """Initialize alert manager.
        
        Args:
            metrics_collector: MetricsCollector instance.
        """
        self.metrics_collector = metrics_collector
        self.thresholds: List[AlertThreshold] = []
        self.active_alerts: List[Alert] = []
        self.alert_handlers: List[Callable[[Alert], None]] = []
        self._lock = threading.Lock()
        self._monitoring = False
        self._monitor_thread = None
        
        # Initialize default thresholds
        self._setup_default_thresholds()
        
    def _setup_default_thresholds(self):
        """Set up default alert thresholds."""
        default_thresholds = [
            AlertThreshold(
                "cpu_usage", 90, AlertSeverity.WARNING, ">=", 300,
                "CPU usage exceeding 90% for 5 minutes"
            ),
            AlertThreshold(
                "memory_usage", 90, AlertSeverity.WARNING, ">=", 300,
                "Memory usage exceeding 90% for 5 minutes"
            ),
            AlertThreshold(
                "error_rate", 10, AlertSeverity.ERROR, ">=", 60,
                "Error rate exceeding 10% for 1 minute"
            ),
            AlertThreshold(
                "request_latency", 2000, AlertSeverity.WARNING, ">=", 60,
                "Average request latency exceeding 2000ms for 1 minute"
            )
        ]
        
        for threshold in default_thresholds:
            self.add_threshold(threshold)
            
    def add_threshold(self, threshold: AlertThreshold):
        """Add a new alert threshold.
        
        Args:
            threshold: AlertThreshold to add.
        """
        with self._lock:
            self.thresholds.append(threshold)
            
    def add_alert_handler(self, handler: Callable[[Alert], None]):
        """Add an alert handler function.
        
        Args:
            handler: Function to call when alert is generated.
        """
        with self._lock:
            self.alert_handlers.append(handler)
            
    def start_monitoring(self, interval: float = 10.0):
        """Start alert monitoring in background thread.
        
        Args:
            interval: Monitoring interval in seconds.
        """
        if self._monitoring:
            return
            
        self._monitoring = True
        self._monitor_thread = threading.Thread(
            target=self._monitor_loop,
            args=(interval,),
            daemon=True
        )
        self._monitor_thread.start()
        logger.info("Alert monitoring started")
        
    def stop_monitoring(self):
        """Stop alert monitoring."""
        self._monitoring = False
        if self._monitor_thread:
            self._monitor_thread.join()
            logger.info("Alert monitoring stopped")
            
    def _monitor_loop(self, interval: float):
        """Main monitoring loop checking thresholds."""
        while self._monitoring:
            try:
                current_time = time.time()
                metrics = self.metrics_collector.get_metrics()
                
                # Check each threshold
                with self._lock:
                    for threshold in self.thresholds:
                        value = self._get_metric_value(metrics, threshold.metric_name)
                        if value is not None and threshold.check(value, current_time):
                            self._handle_threshold_exceeded(threshold, value, current_time)
                            
                    # Check if any active alerts can be resolved
                    self._check_alert_resolution(metrics, current_time)
                    
                time.sleep(interval)
            except Exception as e:
                logger.error(f"Error in alert monitoring loop: {str(e)}")
                time.sleep(interval)
                
    def _get_metric_value(self, metrics: Dict[str, Any], metric_name: str) -> Optional[float]:
        """Get current value for a metric from metrics dictionary.
        
        Args:
            metrics: Metrics dictionary from collector.
            metric_name: Name of metric to retrieve.
            
        Returns:
            Current metric value or None if not found.
        """
        # Check in system metrics
        if metric_name in metrics['system']:
            return metrics['system'][metric_name]
            
        # Check in performance metrics
        if metric_name in metrics['performance']:
            return metrics['performance'][metric_name]
            
        return None
        
    def _handle_threshold_exceeded(self, threshold: AlertThreshold, value: float,
                                 timestamp: float):
        """Handle a threshold being exceeded.
        
        Args:
            threshold: Threshold that was exceeded.
            value: Current value that exceeded threshold.
            timestamp: Time when threshold was exceeded.
        """
        alert = Alert(threshold, value, timestamp)
        self.active_alerts.append(alert)
        
        # Notify all handlers
        for handler in self.alert_handlers:
            try:
                handler(alert)
            except Exception as e:
                logger.error(f"Error in alert handler: {str(e)}")
                
        logger.warning(f"Alert generated: {alert.to_dict()}")
        
    def _check_alert_resolution(self, metrics: Dict[str, Any], timestamp: float):
        """Check if any active alerts can be resolved.
        
        Args:
            metrics: Current metrics dictionary.
            timestamp: Current timestamp.
        """
        resolved = []
        for alert in self.active_alerts:
            if not alert.resolved:
                value = self._get_metric_value(metrics, alert.threshold.metric_name)
                if value is not None and not alert.threshold.check(value, timestamp):
                    alert.resolve(timestamp)
                    resolved.append(alert)
                    logger.info(f"Alert resolved: {alert.to_dict()}")
                    
        # Remove resolved alerts
        self.active_alerts = [a for a in self.active_alerts if not a.resolved]
        
    def get_active_alerts(self) -> List[Dict[str, Any]]:
        """Get list of active alerts.
        
        Returns:
            List of active alerts as dictionaries.
        """
        with self._lock:
            return [alert.to_dict() for alert in self.active_alerts]
            
    def get_alert_history(self) -> List[Dict[str, Any]]:
        """Get history of all alerts.
        
        Returns:
            List of all alerts (active and resolved) as dictionaries.
        """
        with self._lock:
            return [alert.to_dict() for alert in self.active_alerts]

class MetricsExporter:
    """Exports metrics to various formats."""
    
    def __init__(self, metrics_collector: MetricsCollector, export_dir: str = "metrics"):
        """Initialize metrics exporter.
        
        Args:
            metrics_collector: MetricsCollector instance.
            export_dir: Directory to export metrics to.
        """
        self.metrics_collector = metrics_collector
        self.export_dir = Path(export_dir)
        self.export_dir.mkdir(exist_ok=True)

    def export_json(self, filename: str = "metrics.json"):
        """Export metrics to JSON file.
        
        Args:
            filename: Output filename.
        """
        metrics = self.metrics_collector.get_metrics()
        output_path = self.export_dir / filename
        
        with open(output_path, 'w') as f:
            json.dump(metrics, f, indent=2)

    def export_prometheus(self, filename: str = "metrics.prom"):
        """Export metrics in Prometheus format.
        
        Args:
            filename: Output filename.
        """
        metrics = self.metrics_collector.get_metrics()
        output_path = self.export_dir / filename
        
        with open(output_path, 'w') as f:
            # System metrics
            for metric, value in metrics['system'].items():
                if value is not None:
                    f.write(f'ai_detector_system_{metric} {value}\n')
            
            # Performance metrics
            for metric, value in metrics['performance'].items():
                if value is not None:
                    f.write(f'ai_detector_performance_{metric} {value}\n')